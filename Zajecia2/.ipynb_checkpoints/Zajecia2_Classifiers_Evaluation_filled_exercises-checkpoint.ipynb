{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff_analysis(y_test: pd.Series, y_test_hat: pd.Series, cost_matrix: np.array = np.array([[0,0],[0,0]]) ) -> list:\n",
    "    \"\"\"\n",
    "    Calculate accuracy vector for cutoff thresholds between 0 and 1 for given true labels `y_test` \n",
    "    and predicted labels `y_test_hat`. If `cost_matrix` is specified, calculates cost vector instead.\n",
    "    \"\"\"\n",
    "    cutoff_range = np.arange(0, 1.0, 0.01)\n",
    "    vec = []\n",
    "    for cutoff in cutoff_range:\n",
    "        y_test_hat_bin = np.where(y_test_hat >= cutoff, 1, 0)\n",
    "        conf_mat = confusion_matrix(y_test, y_test_hat_bin)\n",
    "        #no cost matrix, calculate accuracy\n",
    "        if np.sum(cost_matrix) == 0:\n",
    "            vec.append(np.sum(np.diag(conf_mat)) / np.sum(conf_mat))\n",
    "        else:\n",
    "            conf_const_mat = np.multiply(conf_mat, cost_matrix)\n",
    "            vec.append(conf_const_mat.sum() / len(y_test))\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Iris dataset from https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv to 'iris' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code `species` column to have value 1 if iris is from _versicolor_ species and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['species'] = np.where(iris['species'] == 'versicolor',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset to train and validation subsets using `train_test_split` function. Training set should have **75%** of all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build logistic regression (with `LogisticRegression` from `sklearn`) using **Elastic-net** regularization with 0.35 L1 ratio (only one solver supports that, check [here](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression))\n",
    "\n",
    "You can read more about **Elastic-net** [here](https://en.wikipedia.org/wiki/Elastic_net_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.35, tol=0.01).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make classification report with `classification_report`. What is accuracy of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why accuracy is so low? If you want to know check [here](https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html#Unsupervised-learning-example:-Iris-dimensionality) below `In[19]`. Plot shows how target classes are distributed in 2D space (which was possible due to dimensionality reduction technique PCA - note that we have 4 predictors (sepal_length/width,petal_length/width) not 2). Remember we merged setosa and virginica species - knowing that look were versicolor is on the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write function \n",
    "\n",
    "`plot_acc_train_vs_val(y_train, y_test, y_train_hat, y_test_hat)` \n",
    "\n",
    "that takes following arguments:\n",
    "\n",
    "- y_train - array of class labels (0 or 1) for training data\n",
    "- y_test - array of class labels (0 or 1) for validation data \n",
    "- y_train_hat - array of probabilities (0 to 1) for class 1 for training data\n",
    "- y_test_hat - array of probabilities (0 to 1) for class 1 for validation data\n",
    "\n",
    "and produce plot like in **Finding optimal cut-off based on ACC** subsection but for both prediction on training and validation data. \n",
    "\n",
    "While creating function you _can_ use code as below:\n",
    "\n",
    "```python\n",
    "    acc_t = cutoff_analysis(y_train, y_train_hat)\n",
    "    acc_v = ...\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Cutoff point\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs. cut-off\")\n",
    "\n",
    "    plt.plot(np.arange(0, 1.0, 0.01), acc_t)\n",
    "    plt.plot(... , linestyle = \":\")\n",
    "    plt.plot([0, 1], [max(acc_t), max(acc_t)], color = 'gray', label = \"Max ACC train= \" + str(round(max(acc_t),3)) + \n",
    "             \" for k = \" + str(np.arange(0, 1.0, 0.01)[acc_t.index(max(acc_t))]))\n",
    "    plt.plot(.....................................)\n",
    "    plt.legend();\n",
    "```\n",
    "\n",
    "Then test your new function using (of course after filling placeholders):\n",
    "\n",
    "```python\n",
    "y_train_hat = model. ...\n",
    "y_test_hat = model. ...\n",
    "plot_acc_train_vs_val(y_train, y_test, y_train_hat, y_test_hat)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_train_vs_val(y_train, y_test, y_train_hat, y_test_hat):\n",
    "    acc_t = cutoff_analysis(y_train, y_train_hat)\n",
    "    acc_v = cutoff_analysis(y_test, y_test_hat)\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Cutoff point\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs. cut-off\")\n",
    "\n",
    "    plt.plot(np.arange(0, 1.0, 0.01), acc_t)\n",
    "    plt.plot(np.arange(0, 1.0, 0.01), acc_v, linestyle = \":\")\n",
    "    plt.plot([0, 1], [max(acc_t), max(acc_t)], color = 'gray', label = \"Max ACC train= \" + str(round(max(acc_t),3)) + \" for k = \" + str(np.arange(0, 1.0, 0.01)[acc_t.index(max(acc_t))]))\n",
    "    plt.plot([0, 1], [max(acc_v), max(acc_v)], color = 'gray', linestyle = \":\", label = \"Max ACC val= \" + str(round(max(acc_v),3)) + \" for k = \" + str(np.arange(0, 1.0, 0.01)[acc_v.index(max(acc_v))]))\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train_hat = model.predict_proba(X_train)[:,1]\n",
    "y_test_hat = model.predict_proba(X_test)[:,1]\n",
    "plot_acc_train_vs_val(y_train, y_test, y_train_hat, y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the plot you may see that accuracy for train and validation sets prediction id quite similar. Shouldn't the accuracy be better on the training set prediction? In this case not necessarily becuase model is **underfitted** - in other words it's biased and may perform better on validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
