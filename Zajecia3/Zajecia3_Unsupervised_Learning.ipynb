{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5640b83",
   "metadata": {},
   "source": [
    "# Class 3 - Unsupervised learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe584af",
   "metadata": {},
   "source": [
    "Unsupervised learning is area of machine learning focused on detecting patterns in the data and **modelling without explicitly set labels/target variable**. In contrast, supervised learning techniques are mainly based on predicting nominal features (classification) or continuous features (regression).\n",
    "\n",
    "Main tasks in the area of unsupervised learning are:\n",
    "- **dimensionality reduction**\n",
    "- **clustering**\n",
    "- anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c95b1d",
   "metadata": {},
   "source": [
    "**Dimensionality reduction** algorithms aim to represent high-dimensional input data in the output space with lower dimensionality. The approach is useful for:\n",
    "- visualization of high dimensional data\n",
    "- removing noise\n",
    "- lowering the volume of the dataset, hence improving performance of other algorithms\n",
    "- obfuscating and anonymizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210cd314",
   "metadata": {},
   "source": [
    "**Clustering** aims to differentiate the groups within the data, usually based on the distance between the observations. It's common task for customer or product datasets - segments created based on clustering results may be used in marketing activities or as an input to supervised machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2ea26",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_array = plt.subplots(1, 5)\n",
    "fig.set_dpi(200)\n",
    "axes = ax_array.flatten()\n",
    "rand = random.sample(range(len(digits['images'])),5)\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.imshow(digits.images[rand[i]], cmap='summer')\n",
    "plt.setp(axes, xticks=[], yticks=[], frame_on=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c733b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the dimensionality of the digits?\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c4d5a",
   "metadata": {},
   "source": [
    "We'll use PCA (Principal Components Analysis) technique to represent 64-dimensional digits data in 2-dimensional space and plot the result.\n",
    "\n",
    "PCA is popular algorithm for dimensionality reduction based on linear algebra. For input matrix (dataset) we need to calculate eigenvectors (principal components) and eigenvalues. Eigenvectors determine directions for projection in new feature space and eigenvalues determine the mangnitude ('importance') of the vectors.\n",
    "![PCA](https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.09-PCA-rotation.png)\n",
    "[source](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)  # PCA model reducing data to 2 dimensions (2 principal components)\n",
    "pca_embedding = pca.fit_transform(digits.data)\n",
    "print(pca_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reduced_data(embedding, color_col):\n",
    "    plt.figure(dpi=150)\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=color_col, cmap='rainbow', s=5)\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    n = len(np.unique(color_col))\n",
    "    plt.colorbar(boundaries=np.arange(n+1)-0.5).set_ticks(np.arange(n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reduced_data(pca_embedding, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9070e",
   "metadata": {},
   "source": [
    "Now let's try a modern dimensionality reduction algorithm called **UMAP** (Uniform Manifold Approximation & Projection). It is rooted in Riemannian geometry - details can be found in the [paper](https://arxiv.org/abs/1802.03426). UMAP proved to give really good results and is considered state-of-the-art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = umap.UMAP(random_state=42)\n",
    "model.fit(digits.data)\n",
    "umap_embedding = model.transform(digits.data)\n",
    "umap_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166267db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reduced_data(umap_embedding, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee635ead",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff8b5c",
   "metadata": {},
   "source": [
    "K-means algorithm in the nutshell:\n",
    "1. Pick randomly 'k' observations from the dataset - initial centroids\n",
    "2. Assign other observations to the nearest centroid\n",
    "3. Calculate average coordinates from the members of the clusters - new coordinates of the center\n",
    "4. Repeat 2. and 3. until stop criterion is reached\n",
    "\n",
    "![kmeans](https://scikit-learn.org/stable/_images/sphx_glr_plot_kmeans_digits_001.png)\n",
    "[source](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64658031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(url, names = ['sepal_length','sepal_width','petal_length','petal_width','species'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = df.species\n",
    "df = df.drop('species', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bf4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(StandardScaler().fit(df).transform(df))\n",
    "# df = pd.DataFrame(StandardScaler().fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(df)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec09a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = umap.UMAP(random_state=42)\n",
    "umap_embedding = model.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reduced_data(umap_embedding, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92f688",
   "metadata": {},
   "source": [
    "**Elbow** method to pick k - inertia for given k-means clustering is the sum of squares between clusters' center and their members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(2,10)\n",
    "inertias = [KMeans(n_clusters=k, random_state=0).fit(df).inertia_ for k in x]\n",
    "plt.figure(dpi = 150)\n",
    "plt.plot(x, inertias,'.-')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xlabel('Number of clusteres');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3_labels = KMeans(n_clusters=3, random_state=0).fit(df).labels_\n",
    "plot_reduced_data(umap_embedding, k3_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea17097",
   "metadata": {},
   "source": [
    "But how to measure quality of the clustering if we have a label to compare to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(species, k3_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = [adjusted_rand_score(species,KMeans(n_clusters=k, random_state=0).fit(df).labels_) for k in x]\n",
    "plt.figure(dpi = 150)\n",
    "plt.plot(x,adrs,'.-')\n",
    "plt.ylabel('Adjusted Rand index')\n",
    "plt.xlabel('Number of clusteres');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558657d",
   "metadata": {},
   "source": [
    "## Homework (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5483c",
   "metadata": {},
   "source": [
    "A) Use 2 other dimensionality reduction techniques (other than PCA nad UMAP) on the digits dataset (2 pts)\n",
    "\n",
    "B) Use 2 other dimensionality reduction techniques (other than PCA nad UMAP) on the other dataset than digits (2 pts)\n",
    "\n",
    "C) Use 1 other clustering technique on Iris dataset plot the results with UMAP as above (1 pt)\n",
    "\n",
    "Please prepare the code in Jupyter notebook and send the notebook to lkrain@sgh.waw.pl with output of the execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
