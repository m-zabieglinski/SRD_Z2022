{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fashion MNIST Github Repo](https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test data\n",
    "((X_train, y_train),(X_test, y_test)) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions check\n",
    "print(\"Fashion MNIST train:\", X_train.shape)\n",
    "print(\"Fashion MNIST test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target labels\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 10 different classes of images:**\n",
    "\n",
    "* **0**: **T-shirt/top**;   \n",
    "* **1**: **Trouser**;   \n",
    "* **2**: **Pullover**;   \n",
    "* **3**: **Dress**;\n",
    "* **4**: **Coat**;\n",
    "* **5**: **Sandal**;\n",
    "* **6**: **Shirt**;\n",
    "* **7**: **Sneaker**;\n",
    "* **8**: **Bag**;\n",
    "* **9**: **Ankle boot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "CLASSES = 10\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "NO_EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check labels distribution in training set\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check labels distribution in test set\n",
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the pixels into [0;1] range\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the train data into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential model with Keras\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Running model training\n",
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=NO_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of accuracy value for training and validation set in each epoch\n",
    "plt.figure(figsize = (10,7))\n",
    "hist = train_model.history\n",
    "x = np.arange(1,21)\n",
    "plt.plot(x, hist['accuracy'], 'o-', label ='train')\n",
    "plt.plot(x, hist['val_accuracy'], 'o-', label = 'validation')\n",
    "plt.xticks(x)\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "plt.title('Convolutional Deep Neural Network')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking fit metrics across all classes\n",
    "predicted_classes = np.argmax(model.predict(X_test), axis=1)\n",
    "labels = {0 : \"T-shirt/top\", 1: \"Trousers\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "target_names = [\"Class {} ({}) :\".format(i, labels[i]) for i in range(CLASSES)]\n",
    "print(classification_report(y_test, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiclass onfusion matrix (heatmap)\n",
    "confmat = pd.crosstab(pd.Series(y_test, name=\"True labels\"),\n",
    "                      pd.Series(predicted_classes, name=\"Predicted labels\"))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(confmat, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As f1-score combine both precision and recall let's focus on analyzing that metric.\n",
    "By looking on f1-score we can see that some classes were predicted better than other.\n",
    "\n",
    "Shirt is similar to T-shirt, so model may have problem with distingushing those two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for deployment\n",
    "model.save('FMNIST_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving first observation from the training data into CSV file\n",
    "np.savetxt('observation.csv', X_train[0]*255, delimiter=',', fmt='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is embedded into Flask web service and exposed on the localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "\n",
    "def load_model():\n",
    "    global model \n",
    "    model = tensorflow.keras.models.load_model('FMNIST_Model.h5')\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"This is Fashion MNIST prediction app. Use <b>/predict</b> endpoint with POST request e.g. <br><br> curl -X POST -F image=@observation.csv 'http://localhost:5000/predict'\"\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "    if flask.request.method == \"POST\":\n",
    "        if flask.request.files.get(\"image\"):\n",
    "            image = np.genfromtxt(flask.request.files[\"image\"], delimiter=',')/255\n",
    "            image = image.reshape(1,28, 28, 1)\n",
    "            preds = model.predict(image).tolist()[0]\n",
    "            data[\"predictions\"] = []\n",
    "            for (label, prob) in enumerate(preds):\n",
    "                r = {\"label\": label, \"probability\": float(prob)}\n",
    "                data[\"predictions\"].append(r)\n",
    "            data[\"success\"] = True\n",
    "\n",
    "    return flask.jsonify(data)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"* Loading Keras model and Flask server...\")\n",
    "    load_model()\n",
    "    app.run(host='0.0.0.0',threaded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -F image=@observation.csv 'http://localhost:5000/predict' | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app can also be launched in terminal by switching working directory to `keras-app` folder and running\n",
    "```shell\n",
    "python app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the model deployment maintainable and scalable, the app can be containerized e.g. using Docker. Containers are easy to distribute and run on multiple machines. The containers can also be run on public cloud services such as [Cloud Run](https://cloud.google.com/run) - the managed services make it easier to monitor and maintain the ML applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -F image=@observation.csv 'https://fmnist-service-gkgytk6vja-lm.a.run.app/predict' | jq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
